{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "JB0baaCbkbge",
    "outputId": "af9b8ef5-3807-48b1-fcad-e322a98b4107",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  vgg-train.zip\n",
      "replace vgg-train/test/1/00010257.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import copy\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "#import customDataset\n",
    "#from customDataset import CustomDataset\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "# for google colab runs\n",
    "!unzip \"vgg-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LAv8YfDKkbgh",
    "outputId": "ebe99a1a-df9a-4f4f-f9a2-ab0f8b5659df",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "W4yj2_OTkbgn",
    "outputId": "9602a60b-bb3a-4cd4-e72b-20a077916f85",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 294 images under train\n",
      "Loaded 125 images under val\n",
      "Loaded 125 images under test\n",
      "Classes: \n",
      "['0', '1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'vgg-train'\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: dset.ImageFolder(\n",
    "        osp.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=16,\n",
    "        shuffle=True    \n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "for x in [TRAIN, VAL, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqwLcIhWkbgw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRGzYCagkbgy",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10, save=False, save_filename=\"\"):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "    \n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    val_batches = len(dataloaders[VAL])\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "        \n",
    "        for i, data in enumerate(dataloaders[TRAIN]):\n",
    "            if i % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "                \n",
    "            # Use half training dataset\n",
    "#             if i >= train_batches / 2:\n",
    "#                 break\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#             print(\"preds: \", preds)\n",
    "#             print(\"labels.data: \", labels.data)\n",
    "#             print(preds == labels.data)\n",
    "#             print()\n",
    "            \n",
    "            loss_train += loss.data\n",
    "            acc_train += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        #print()\n",
    "        # * 2 as we only used half of the dataset\n",
    "        avg_loss = loss_train  / dataset_sizes[TRAIN]\n",
    "        avg_acc = acc_train.item()  / dataset_sizes[TRAIN]\n",
    "        \n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "            \n",
    "        for i, data in enumerate(dataloaders[VAL]):\n",
    "#             if i % 10 == 0:\n",
    "#                 print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_val += loss.data\n",
    "            acc_val += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "        avg_acc_val = acc_val.item() / dataset_sizes[VAL]\n",
    "        \n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch + 1))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "        print('-' * 10)\n",
    "#         print(\"avg_acc_val\", avg_acc_val)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    if(save):\n",
    "      torch.save(best_model_wts, save_filename)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "1VK-xI_okbg1",
    "outputId": "241d832d-bdc9-40bb-f69b-15bc87ef7183",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 result: \n",
      "Avg loss (train): 0.1492\n",
      "Avg acc (train): 0.3537\n",
      "Avg loss (val): 0.1118\n",
      "Avg acc (val): 0.3840\n",
      "----------\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "\n",
      "Epoch 2 result: \n",
      "Avg loss (train): 0.1484\n",
      "Avg acc (train): 0.3367\n",
      "Avg loss (val): 0.1436\n",
      "Avg acc (val): 0.3920\n",
      "----------\n",
      "\n",
      "\n",
      "Training completed in 1m 21s\n",
      "Best acc: 0.3920\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "def get_vgg19(num_classes):\n",
    "    net = models.vgg19_bn(pretrained=False)\n",
    "    net.classifier = nn.Sequential(\n",
    "        nn.Linear(25088, 4096),\n",
    "        nn.ReLU(True),\n",
    "        #nn.BatchNorm1d(4096),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 2048),\n",
    "        nn.ReLU(True),\n",
    "        #nn.BatchNorm1d(2048),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(2048, num_classes),\n",
    "    )\n",
    "    return net.type(gpu_dtype)\n",
    "\n",
    "vgg19 = get_vgg19(6) #this fixes the issue where vgg outputs 1000 classifiers and now outputs n classifiers in get_vgg(n)\n",
    "vgg19.cuda()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg19.parameters(), lr=0.005, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "vgg19 = train_model(vgg19, loss_fn, optimizer, exp_lr_scheduler, num_epochs=2)\n",
    "#saved version // remember to change the filename and follow naming scheme\n",
    "#vgg19 = train_model(vgg19, loss_fn, optimizer, exp_lr_scheduler, num_epochs=125, save=True, save_filename='VGG16_bn_125e_adam05.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "tA5dztjlkbhA",
    "outputId": "e6282df1-886f-4b02-dd14-da537acc3bbe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5])\n",
      "Got 96 / 294 correct (32.65)\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(model, loader):\n",
    "#     if loader.dataset.train:\n",
    "#         print('Checking accuracy on validation set')\n",
    "#     else:\n",
    "#         print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.train(False)\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in loader:\n",
    "        x_var = Variable(x.type(gpu_dtype), volatile=True)\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        print(preds)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    \n",
    "    \n",
    "check_accuracy(vgg19, dataloaders[TRAIN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "DTQIOl-EkbhD",
    "outputId": "0287391d-b282-4efa-d813-72b17fa6843f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "Got 49 / 125 correct (39.20)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(vgg19, dataloaders[VAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "5JOtWiKGkbhG",
    "outputId": "9c3662f1-403f-4f31-bc48-889e89b69d21",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "Got 47 / 125 correct (37.60)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(vgg19, dataloaders[TEST])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
